# 集群配置方式

Hadoop 集群可以运行的 3 个模式有：

- 单机模式
- 伪分布模式
- 全分布模式

## 单机模式

默认情况下，Hadoop被配置成以非分布式模式运行的一个独立Java进程。这对调试非常有帮助。

不会存在守护进程，所有东西都运行在一个 JVM 上，这里同样没有 HDFS，使用的是本地文件系统。

> 官方案例 grep

```bash
# 在文件安装路径下新建input
$ cp etc/hadoop/*.xml input/
# 执行命令
$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.2.jar grep input/ output 'dfs[a-z.]+'
# output 不可以提前创建
```

> 官方案例 word count

```bash
$ mkdir wcinput
$ vi wc.input
# 输入一些字母
# 执行
$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.2.jar wordcount wcinput/ wcoutput
```

## 伪分布模式

### Hadoop配置

修改`hadoop-env.sh`

```bash
# 修改JAVA_HOME 地址
export JAVA_HOME=/opt/module/jdk1.8.0_201
```

修改 `core-site.xml`

```xml
<configuration>
    <!-- 修改Hadoop的NameNode的地址 -->
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://localhost:9000</value>
    </property>
    <!-- 指定Hadoop运行时候的产生文件的临时存储目录 -->
      <property>
        <name>hadoop.tmp.dir</name>
        <value>/opt/module/hadoop-2.9.2/data/tmp</value>
    </property>
</configuration>
```

修改`hdfs-site.xml`

```xml
<configuration>
    <!-- 指定hdfs副本的数量，默认值3，保存数据的副本，防止数据丢失 -->
    <property>
        <name>dfs.replication</name>
        <value>1</value>
    </property>
</configuration>
```

### 配置和启动HDFS服务

第一次启动需要格式化，以后不需要再格式化，需要关闭服务，删除data和log文件夹再次格式化。

**原因**：格式化`namenode` 会产生新的集群id，导致和`datanode`不一致。

```bash
# 格式化namenode	
$ bin/hdfs namenode -format
# 启动namenode
$ sbin/hadoop-daemon.sh start namenode
# 启动datanode
$ sbin/hadoop-daemon.sh start datanode
# 查看是否启动
$ jps
# 结果
7634 NameNode
7690 DataNode
7770 Jps
```

查看控制面板，端口号为**50070**

![面板](assets/20190308194111.png)

*注意*：**若打不开，请查看防火墙**

#### HDFS的操作

**例1：创建文件夹**

```bash
# 创建文件夹
$ bin/hdfs dfs -mkdir -p /user/fanl/input
# 创建完查看目录，已经存在路径，和linux命令是一致的 其中，bin/hdfs dfs 是固定的写法
```

![控制板](assets/20190308195627.png)

**例2：复制本地文件到HDFS**

```bash
$ bin/hdfs dfs -put input/fanl.txt /user/fanl/input
```

**例3：执行wordcount**

```bash
$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.2.jar wordcount /user/fanl/input/ /user/fanl/output
# 查看结果
$ bin/hdfs dfs -cat /user/fanl/output/*
```

### 配置和启动YARN服务

修改`yarn-env.sh`

```bash
# 修改JAVA_HOME地址
export JAVA_HOME=/opt/module/jdk1.8.0_201
```

修改`yarn-site.xml`

```xml
<configuration>
    <!-- MapReduce获取数据的方式 -->
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
    <!-- YARN的resourcemanager的地址 -->
     <property>
        <name>yarn.resourcemanager.hoastname</name>
        <value>fanl01</value>
    </property>
</configuration>
```

### 配置MapReduce服务

修改`mapred-env.sh`

```bash
# 修改JAVA_HOME地址
export JAVA_HOME=/opt/module/jdk1.8.0_201
```

修改`mapred-site.xml`

```xml
<configuration>
    <!-- 指定MR运行在YARN上 -->
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
</configuration>
```

启动yarn

```bash
$ sbin/yarn-daemon.sh start resourcemanager
$ sbin/yarn-daemon.sh start nodemanager
# 查看启动
8272 ResourceManager
7634 NameNode
8322 NodeManager
7690 DataNode
8397 Jps
```

查看控制面板，端口号为 **8088**

```bash
$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.2.jar wordcount /user/fanl/input/ /user/fanl/output
# 并且查看控制面板
```

### 配置和启动历史服务器

修改`mapred-site.xml`

```xml
<configuration>
    <!--历史服务器地址-->
    <property>
        <name>mapreduce.jobhistory.address</name>
        <value>fanl01:10020</value>
    </property>
    <!--历史服务器地址WEB地址-->
     <property>
        <name>mapreduce.jobhistory.webapp.address</name>
        <value>fanl01:19888</value>
    </property>
</configuration>
```

启动历史服务器`historyserver`

```bash
$  sbin/mr-jobhistory-daemon.sh start historyserver
```

#### 配置日志聚集

修改`yarn-site.xml`，若启动中，需要重启**yarn**和**historyserver**。

```xml
<configuration>
    <!-- 开启日志聚集 -->
    <property>
        <name>yarn.log-aggregation-enable</name>
        <value>true</value>
    </property>
    <!-- 日志聚集保留时间 30天,实际可以是180 -->
     <property>
        <name>yarn.log-aggregation.retain-seconds</name>
        <value>2592000</value>
    </property>
</configuration>
```

### 启动和关闭脚本编写

```bash
#!/bin/bash
# 启动hadoop
echo ++++ 启动Hadoop伪分布的集群进程 ++++
echo -----------------------------------
echo Hadoop安装目录： $HADOOP_HOME
$HADOOP_HOME/sbin/hadoop-daemon.sh start namenode
$HADOOP_HOME/sbin/hadoop-daemon.sh start datanode
$HADOOP_HOME/sbin/yarn-daemon.sh start resourcemanager
$HADOOP_HOME/sbin/yarn-daemon.sh start nodemanager
$HADOOP_HOME/sbin/mr-jobhistory-daemon.sh start historyserver
jps
```

## 全分布模式

### 分发脚本的编写

实现各个服务器于主服务器文件的同步，注意文件夹的权限问题。

```bash
[fanl@hadoop1 ~]$ mkdir bin
[fanl@hadoop1 ~]$ cd bin/
[fanl@hadoop1 bin]$ touch xsync
```

`xsync`脚本：

```bash
#!/bin/bash
# 获取输入的参数，没有参数，直接退出
param_count=$#
if [ ${param_count} == 0 ];then
   echo "请输路径参数"
else
   # 获取文件名
   filename=`basename $1`
   echo "文件名为："${filename}
   # 取得绝对路径
   real_path=`cd -P $(dirname $1);pwd`
   echo "真实路径为"${real_path}
   # 获取当前登录用户
   user=`whoami`
   # 循环传输文件
   for((i=2;i<=3;i++));do
      echo "=======Hadoop-HOST${i}============"
      rsync -rvl ${real_path}/${filename} ${user}@hadoop${i}:${real_path}
   done
fi
```

### 集群配置和启动

#### 集群规划

假设的3台服务器按照如下规划Hadoop的部署。

| 组件 | hadoop1              | hadoop2         | hadoop3                        |
| ---- | -------------------- | --------------- | ------------------------------ |
| HDFS | NameNode<br>DataNode | DataNode        | SecondaryNameNode<br/>DataNode |
| YARN | NodeManager          | ResourceManager | NodeManager                    |

#### 集群配置

##### 核心文件配置

首先在主服务器上需要修改`*-env.sh`的`JDK`的环境变量。

```bash
[fanl@hadoop2 hadoop-2.9.2]$ vi hadoop-env.sh
[fanl@hadoop2 hadoop-2.9.2]$ vi yarn-env.sh
[fanl@hadoop2 hadoop-2.9.2]$ vi mapred-env.sh
```

然后修改各个配置文件

- core-site.xml
- hdfs-site.xml
- yarn-site.xml

###### Hadoop配置

core-site.xml

```xml
<configuration>
    <!--修改Hadoop的NameNode的地址-->
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://hadoop1:9000</value>
    </property>
    <!--指定Hadoop运行时候的产生文件的临时存储目录-->
      <property>
        <name>hadoop.tmp.dir</name>
        <value>/opt/module/hadoop-2.9.2/data/tmp</value>
    </property>
</configuration>
```

###### HDFS配置

hdfs-site.xml

```xml
<configuration>
    <!--指定hdfs副本的数量，默认值3，保存数据的副本，防止数据丢失-->
    <property>
        <name>dfs.replication</name>
        <value>3</value>
    </property>
    <!--指定NameNode辅助程序的节点-->
     <property>
        <name>dfs.namenode.secondary.http-address</name>
        <value>hadoop3:50090</value>
     </property>
</configuration>
```

###### YARN的配置

yarn-site.xml

```xml
<configuration>
    <!--MapReduce获取数据的方式-->
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
    <!--YARN的resourcemanager的地址-->
     <property>
        <name>yarn.resourcemanager.hoastname</name>
        <value>hadoop2</value>
    </property>
</configuration>
```

mapred-site.xml

```xml
<configuration>
    <!--指定MR运行在YARN上-->
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
</configuration>
```

##### 集群的单点启动测试

首先检查是否删除了临时文件和日志信息。然后格式化**datanode**

```bash
# 启动hdfs
# 节点hadoop1
[fanl@hadoop2 hadoop-2.9.2]$ bin/hdfs namenode -format
[fanl@hadoop2 hadoop-2.9.2]$ sbin/hadoop-daemon.sh start namenode
[fanl@hadoop2 hadoop-2.9.2]$ sbin/hadoop-daemon.sh start datanode
# 节点hadoop2 和 hadoop3
[fanl@hadoop2 hadoop-2.9.2]$ sbin/hadoop-daemon.sh start datanode
# 测试地址：http://hadoop1:50070
# 启动yarn，必须在rm部署的节点启动rm
# 在hadoop2节点启动yarn
[fanl@hadoop2 hadoop-2.9.2]$ sbin/yarn-daemon.sh start resourcemanager
# 其他节点
[fanl@hadoop2 hadoop-2.9.2]$ sbin/yarn-daemon.sh start nodemanager
# 测试地址：http://hadoop2:8088
```

##### 集群群起

```bash
# 修改配置文件 had0op-xxx/etc/haddop/slaves 存放datanode节点
# 增加主机信息 不可有空格
hadoop1
hadoop2
hadoop3
# 群起HDFS
[fanl@hadoop1 hadoop-2.9.2]$ sbin/start-dfs.sh
#群起YARN,必须在规划RM的节点启动
[fanl@hadoop2 hadoop-2.9.2]$ sbin/start-yarn.sh
```

##### 集群测试

```bash
[fanl@hadoop2 hadoop-2.9.2]$ bin/hdfs dfs /opt/software/jdk.tar.gz /
```

上传一个大文件和大于128M的文件，观察其存储位置和大小，并且尝试拼接块。

![](assets/20190313183152.png)

实际存储的路径

![](assets/20190313183739.png)

尝试将标记的块合并到一个文件中，并且解压，会发现此文件正是之前上传的大文件。

##### 集群时间同步

